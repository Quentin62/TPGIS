{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NIPALS\n",
    "\n",
    "- *Auteurs :* Quentin Grimonprez, Cristian Preda, Vincent Vandewalle\n",
    "- *Date :* 3 février 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "plt.style.use(\"seaborn\")\n",
    "plt.rcParams[\"figure.figsize\"] = 8, 8\n",
    "rng = np.random.default_rng(42)  # fixer le seed de l'aléatoire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "p = 4\n",
    "mu = [1, 2, 4, 3]\n",
    "cov = [[0.7, 0, 1.3, 0.5],\n",
    "       [0, 1.2, -0.3, -0.1],\n",
    "       [1.3, -0.3, 3.1, 1.3],\n",
    "       [0.5, -0.1, 1.3, 0.6]]\n",
    "\n",
    "X = rng.multivariate_normal(mu, cov, n)\n",
    "X[:10, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On vérifie que les données sont \"bien\" simulées :\n",
    "- Les moyennes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(np.mean(X, axis=0), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La matrice de variance-covariance :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(np.cov(X.T), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACP normée sur les données simulées.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = X.std(axis=0, ddof=0)\n",
    "X_scaled = X / sd\n",
    "X_scaled[:10, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=4)\n",
    "pca.fit(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- valeurs propres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- facteurs principaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- composantes principales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = pca.transform(X_scaled)\n",
    "comp[:10, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn ne propose pas de fonctions graphiques pour l'ACP. Nous écrivons donc ces fonctions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_explained_variance(pca, cumulative=False):\n",
    "    _, ax = plt.subplots()\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "    if cumulative:\n",
    "        cumul_ratio = np.cumsum(pca.explained_variance_ratio_)\n",
    "        ax.bar(range(len(cumul_ratio) + 1), np.concatenate(([0], cumul_ratio)))\n",
    "        ax.set_ylabel(\"Cumulative explained variance ratio\")\n",
    "        ax.set_title(\"Cumulative explained variance ratio\")\n",
    "    else:\n",
    "        ax.bar(range(1, len(pca.explained_variance_ratio_) + 1), pca.explained_variance_ratio_)\n",
    "        ax.set_ylabel(\"Explained variance ratio\")\n",
    "        ax.set_title(\"Explained variance ratio\")\n",
    "\n",
    "    ax.set_xlabel(\"Number of components\")\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_individuals(score, comp=[0, 1]):\n",
    "    _, ax = plt.subplots()\n",
    "    ax.axhline(y=0, color=\"k\", lw=1, ls=\"--\")\n",
    "    ax.axvline(x=0, color=\"k\", lw=1, ls=\"--\")\n",
    "    ax.scatter(score[:, comp[0]], score[:, comp[1]])\n",
    "    ax.set_xlabel(\"Dim \" + str(comp[0]))\n",
    "    ax.set_ylabel(\"Dim \" + str(comp[1]))\n",
    "    ax.set_title(\"PCA graph of individuals\")\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def get_var_contribution(pca):\n",
    "    return pca.components_ * np.sqrt(pca.explained_variance_[:pca.n_components_]).reshape(-1, 1)\n",
    "\n",
    "\n",
    "def plot_variables(pca, comp=[0, 1], label=None):\n",
    "    _, ax = plt.subplots()\n",
    "\n",
    "    if label is None:\n",
    "        label = [\"V\" + str(i) for i in range(pca.n_features_)]\n",
    "\n",
    "    var_contrib = get_var_contribution(pca)\n",
    "\n",
    "    # plot circle + axis\n",
    "    an = np.linspace(0, 2 * np.pi, 100)\n",
    "    ax.plot(np.cos(an), np.sin(an), color=\"k\")\n",
    "    ax.axhline(y=0, color=\"k\", lw=1, ls=\"--\")\n",
    "    ax.axvline(x=0, color=\"k\", lw=1, ls=\"--\")\n",
    "\n",
    "    # plot arrow + text\n",
    "    for i in range(pca.n_features_):\n",
    "        ax.arrow(0, 0,\n",
    "                  var_contrib[comp[0], i], var_contrib[comp[1], i],\n",
    "                  head_width=0.01, head_length=0.01)\n",
    "\n",
    "        ax.text(var_contrib[comp[0], i] + 0.025,\n",
    "                 var_contrib[comp[1], i] + 0.025,\n",
    "                 label[i])\n",
    "\n",
    "    ax.set_xlabel(\"Dim \" + str(comp[0]) + \" (\" + str(round(pca.explained_variance_ratio_[comp[0]] * 100, 2)) + \"%)\")\n",
    "    ax.set_ylabel(\"Dim \" + str(comp[1]) + \" (\" + str(round(pca.explained_variance_ratio_[comp[1]] * 100, 2)) + \"%)\")\n",
    "    ax.set_title(\"PCA graph of variables\")\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_explained_variance(pca, cumulative=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_individuals(comp, [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_variables(pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NIPALS sans traitement des données manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NIPALS(X, h=2, iter=100):\n",
    "    # renvoie les composantes principales (CP), les facteurs principaux (FP) et les données reconstituées avec h composantes (Xrec)\n",
    "    n, p = X.shape\n",
    "\n",
    "    # centrer et réduire matrice X\n",
    "    m = X.mean(axis=0)\n",
    "    s = X.std(axis=0, ddof=0)\n",
    "    X_reduit = (X - m) / s\n",
    "\n",
    "    # on réserve la place pour:\n",
    "    CP = np.zeros((n, h))  # les composantes principales\n",
    "    FP = np.zeros((h, p))  # les facteurs principaux\n",
    "    X_recons = np.zeros((n, p))  # les données reconstituées\n",
    "\n",
    "    # déroulement de l'algorithme:\n",
    "    for i in range(h):\n",
    "        # voir pages 30-32 du cours\n",
    "        cp, fp = calcul_cp_fp(X_reduit, iter)  # fonction qui calcule la 1ere comp. princ et 1er fact. principal\n",
    "        CP[:, i] = cp\n",
    "        FP[i, :] = fp\n",
    "        X_reduit -= np.matmul(cp.reshape(-1, 1), fp.reshape(1, -1))\n",
    "\n",
    "    # Reconstitution des données avec h composantes\n",
    "    X_recons = np.matmul(CP, FP)\n",
    "    X_recons *= s\n",
    "    X_recons += m\n",
    "\n",
    "    return CP, FP, X_recons\n",
    "\n",
    "\n",
    "def calcul_cp_fp(X, iter=100):\n",
    "    cp = X[:, 0].copy()\n",
    "    fp = np.zeros((X.shape[1], ))\n",
    "    for i in range(iter):\n",
    "        fp = np.matmul(X.T, cp)\n",
    "\n",
    "        # on normalize fp:\n",
    "        fp /= np.sqrt(np.sum(fp**2))\n",
    "        cp = np.matmul(X, fp)\n",
    "\n",
    "    return cp, fp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application de NIPALS aux données simulées\n",
    "Voici ce qu'on obtient avec h=4 composantes. À comparer avec ce qui est donné par scikit-learn dans l'objet 'pca'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp, fp, X_rec = NIPALS(X, h=p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les facteurs principaux :\n",
    "- nipals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les composantes principales :\n",
    "- nipals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp[:6, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp[:6, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### La reconstitution complète des données (toutes les composantes principales) \n",
    "\n",
    "La reconstitution des données avec toutes les composantes principales.\n",
    "- Données reconstituées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rec[:6, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:6, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approximation des données avec quelques composantes (ici h=2)\n",
    "\n",
    "Voici la reconstitution des données avec juste deux composantes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp, fp, X_rec = NIPALS(X, h=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Données reconstituées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rec[:6, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:6, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NIPALS avec données manquantes.\n",
    "L'algorithme précédent est adapté aux cas où il n'y a pas de données manquantes. Les points à modifier sont au niveau du :\n",
    "\n",
    "  - calcul des moyennes (m) et écart-types (s)\n",
    "  - calcul des composantes et facteurs dans la fonction calcul_cp_fp\n",
    "\n",
    "On ré-écrit donc ces fonctions en les renommant : *NIPALS_dm* et *calcul_cp_fp_dm*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NIPALS_dm(X, h=2, iter=100):\n",
    "    # renvoie les composantes principales (CP), les facteurs principaux (FP) et les données reconstituées avec h composantes (Xrec)\n",
    "    n, p = X.shape\n",
    "\n",
    "    # centrer et réduire matrice X\n",
    "    m = np.nanmean(X, axis=0)\n",
    "    s = np.nanstd(X, axis=0, ddof=0)\n",
    "    X_reduit = (X - m) / s\n",
    "\n",
    "    # on réserve la place pour:\n",
    "    CP = np.zeros((n, h))  # les composantes principales\n",
    "    FP = np.zeros((h, p))  # les facteurs principaux\n",
    "    X_recons = np.zeros((n, p))  # les données reconstituées\n",
    "\n",
    "    # déroulement de l'algorithme:\n",
    "    for i in range(h):\n",
    "        # voir pages 30-32 du cours\n",
    "        cp, fp = calcul_cp_fp_dm(X_reduit, iter)  # fonction qui calcule la 1ere comp. princ et 1er fact. principal\n",
    "        CP[:, i] = cp\n",
    "        FP[i, :] = fp\n",
    "        X_reduit -= np.matmul(cp.reshape(-1, 1), fp.reshape(1, -1))\n",
    "\n",
    "    # Reconstitution des données avec h composantes\n",
    "    X_recons = np.matmul(CP, FP)\n",
    "    X_recons *= s\n",
    "    X_recons += m\n",
    "\n",
    "    return CP, FP, X_rec\n",
    "\n",
    "\n",
    "def calcul_cp_fp_dm(X, iter=100):\n",
    "    cp = X[:, 0].copy()\n",
    "    fp = np.zeros((X.shape[1], ))\n",
    "    for i in range(iter):\n",
    "        for j in range(X.shape[1]):\n",
    "            fp[j] = np.nansum(X[:, j] * cp)\n",
    "\n",
    "        # on normalize fp:\n",
    "        fp /= np.sqrt(np.sum(fp**2))\n",
    "\n",
    "        for j in range(X.shape[0]):\n",
    "            cp[j] = np.nansum(X[j, :] * fp)\n",
    "\n",
    "    return cp, fp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On vérifie que la version modifiée *NIPALS_dm* donne les mêmes résultats que *NIPALS* lorsqu'il n'y a pas données manquantes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_dm, fp_dm, X_rec_dm = NIPALS_dm(X, h=p)\n",
    "cp, fp, X_rec = NIPALS(X, h=p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les facteurs principaux :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les composantes principales :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_dm[:6, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp[:6, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données reconstituées :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rec_dm[:6, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rec[:6, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parfait!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation des données manquantes sur la matrice X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pourcentage des données manquantes\n",
    "prop_miss = 0.1\n",
    "# génération des valeurs manquantes\n",
    "X_miss = X.copy()\n",
    "ind = rng.random((n, p))\n",
    "is_missing = ind < prop_miss\n",
    "X_miss[is_missing] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nombre de manquants par colonne :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(X_miss).sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici les valeurs qui ont été déclarées manquantes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[is_missing]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation des valeurs manquantes avec NIPALS :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_imp, fp_imp, X_rec_imp = NIPALS_dm(X_miss, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici les valeurs estimées par NIPALS pour les données manquantes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rec_imp[is_missing]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cela a l'air pas mal!"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
